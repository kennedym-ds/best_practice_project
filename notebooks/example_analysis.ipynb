{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdbce8f4",
   "metadata": {},
   "source": [
    "# Data Analysis Pipeline Example\n",
    "\n",
    "This notebook demonstrates the complete data analysis pipeline using the `data_analysis` package.\n",
    "\n",
    "## Pipeline Steps:\n",
    "1. **Load Data** - Import data from various formats (CSV, Excel, JSON)\n",
    "2. **Clean Data** - Handle missing values, duplicates, and outliers\n",
    "3. **Analyze Data** - Perform statistical analysis and correlation studies\n",
    "4. **Visualize Data** - Create meaningful visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cb7e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from data_analysis import DataLoader, DataCleaner, DataAnalyzer, Visualizer\n",
    "\n",
    "# Set up paths\n",
    "data_dir = Path('../data/raw')\n",
    "output_dir = Path('../data/processed')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Configure matplotlib for inline plotting\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfa6066",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "We'll load employee data from a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf10be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataLoader\n",
    "loader = DataLoader()\n",
    "\n",
    "# Load employee data\n",
    "employees_df = loader.load_csv(data_dir / 'employees.csv')\n",
    "\n",
    "print(f\"Loaded {len(employees_df)} employee records\")\n",
    "print(f\"\\nColumns: {list(employees_df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "employees_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbd5538",
   "metadata": {},
   "source": [
    "## 2. Data Inspection\n",
    "\n",
    "Let's examine the data types and basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cc5b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "print(\"Data types:\")\n",
    "print(employees_df.dtypes)\n",
    "print(\"\\nBasic statistics:\")\n",
    "employees_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fde91c",
   "metadata": {},
   "source": [
    "## 3. Clean Data\n",
    "\n",
    "Convert data types and check for missing values or duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97019a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataCleaner\n",
    "cleaner = DataCleaner(employees_df)\n",
    "\n",
    "# Convert hire_date to datetime\n",
    "cleaner.convert_dtypes({'hire_date': 'datetime64[ns]'})\n",
    "\n",
    "# Check for missing values\n",
    "missing = cleaner.df.isnull().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing[missing > 0] if missing.sum() > 0 else \"No missing values found\")\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = cleaner.df.duplicated().sum()\n",
    "print(f\"\\nDuplicate rows: {duplicates}\")\n",
    "\n",
    "# Get cleaned data\n",
    "clean_df = cleaner.get_data()\n",
    "print(f\"\\nCleaned data shape: {clean_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80679c5",
   "metadata": {},
   "source": [
    "## 4. Statistical Analysis\n",
    "\n",
    "Perform various statistical analyses on the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e06afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataAnalyzer\n",
    "analyzer = DataAnalyzer(clean_df)\n",
    "\n",
    "# Get summary statistics\n",
    "print(\"=== Summary Statistics ===\")\n",
    "summary = analyzer.get_summary_statistics()\n",
    "display(summary)\n",
    "\n",
    "# Analyze by department\n",
    "print(\"\\n=== Analysis by Department ===\")\n",
    "dept_analysis = analyzer.group_analysis(\n",
    "    group_column='department',\n",
    "    agg_columns=['salary', 'age', 'performance_score'],\n",
    "    agg_funcs=['mean', 'median', 'std', 'count']\n",
    ")\n",
    "display(dept_analysis)\n",
    "\n",
    "# Get correlation matrix for numeric columns\n",
    "print(\"\\n=== Correlation Analysis ===\")\n",
    "numeric_cols = ['age', 'salary', 'performance_score']\n",
    "correlations = analyzer.get_correlation_matrix(columns=numeric_cols)\n",
    "display(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2694dd",
   "metadata": {},
   "source": [
    "## 5. Visualizations\n",
    "\n",
    "Create various visualizations to understand the data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fbb428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Visualizer\n",
    "viz = Visualizer(clean_df)\n",
    "\n",
    "# Create salary distribution histogram\n",
    "print(\"Creating salary distribution histogram...\")\n",
    "viz.create_histogram(\n",
    "    column='salary',\n",
    "    bins=10,\n",
    "    title='Salary Distribution',\n",
    "    xlabel='Salary ($)',\n",
    "    ylabel='Frequency',\n",
    "    kde=True\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f6e327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boxplot for salary by department\n",
    "print(\"Creating salary by department boxplot...\")\n",
    "viz.create_boxplot(\n",
    "    column='salary',\n",
    "    title='Salary Distribution by Department',\n",
    "    ylabel='Salary ($)',\n",
    "    groupby='department'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c27650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot of age vs salary\n",
    "print(\"Creating age vs salary scatter plot...\")\n",
    "viz.create_scatter(\n",
    "    x='age',\n",
    "    y='salary',\n",
    "    title='Age vs Salary',\n",
    "    xlabel='Age',\n",
    "    ylabel='Salary ($)',\n",
    "    hue='department'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eda15dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation heatmap\n",
    "print(\"Creating correlation heatmap...\")\n",
    "viz.create_correlation_heatmap(\n",
    "    columns=numeric_cols,\n",
    "    title='Correlation Matrix: Age, Salary, and Performance',\n",
    "    annot=True,\n",
    "    cmap='coolwarm'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad53cd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar plot of average salary by department\n",
    "print(\"Creating average salary by department bar plot...\")\n",
    "dept_salaries = clean_df.groupby('department')['salary'].mean().reset_index()\n",
    "viz_dept = Visualizer(dept_salaries)\n",
    "viz_dept.create_bar_plot(\n",
    "    x='department',\n",
    "    y='salary',\n",
    "    title='Average Salary by Department',\n",
    "    xlabel='Department',\n",
    "    ylabel='Average Salary ($)'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a5b8ff",
   "metadata": {},
   "source": [
    "## 6. Advanced Analysis\n",
    "\n",
    "Perform regression analysis and outlier detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b38696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression: predict salary based on age\n",
    "print(\"=== Linear Regression: Salary ~ Age ===\")\n",
    "slope, intercept, r_squared = analyzer.simple_linear_regression(x='age', y='salary')\n",
    "print(f\"Slope: {slope:.2f}\")\n",
    "print(f\"Intercept: {intercept:.2f}\")\n",
    "print(f\"R² Score: {r_squared:.4f}\")\n",
    "print(f\"\\nInterpretation: For each additional year of age, salary increases by ${slope:.2f}\")\n",
    "\n",
    "# Detect salary outliers\n",
    "print(\"\\n=== Outlier Detection (Salary) ===\")\n",
    "outliers_zscore = analyzer.detect_anomalies(column='salary', method='zscore', threshold=2.0)\n",
    "outliers_iqr = analyzer.detect_anomalies(column='salary', method='iqr')\n",
    "\n",
    "print(f\"Outliers detected (Z-score method): {len(outliers_zscore)}\")\n",
    "if len(outliers_zscore) > 0:\n",
    "    print(\"Outlier records:\")\n",
    "    display(clean_df.loc[outliers_zscore, ['name', 'department', 'salary']])\n",
    "\n",
    "print(f\"\\nOutliers detected (IQR method): {len(outliers_iqr)}\")\n",
    "if len(outliers_iqr) > 0:\n",
    "    print(\"Outlier records:\")\n",
    "    display(clean_df.loc[outliers_iqr, ['name', 'department', 'salary']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc292dc",
   "metadata": {},
   "source": [
    "## 7. Save Results\n",
    "\n",
    "Save the cleaned data and analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89298db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data\n",
    "output_file = output_dir / 'employees_cleaned.csv'\n",
    "loader.save_csv(clean_df, output_file)\n",
    "print(f\"Cleaned data saved to: {output_file}\")\n",
    "\n",
    "# Save department analysis\n",
    "dept_file = output_dir / 'department_analysis.csv'\n",
    "loader.save_csv(dept_analysis, dept_file)\n",
    "print(f\"Department analysis saved to: {dept_file}\")\n",
    "\n",
    "# Save visualizations\n",
    "viz_dir = Path('../outputs/visualizations')\n",
    "viz_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "viz.create_histogram('salary', bins=10, kde=True, save_path=viz_dir / 'salary_dist.png')\n",
    "viz.create_correlation_heatmap(numeric_cols, annot=True, save_path=viz_dir / 'correlation_heatmap.png')\n",
    "print(f\"\\nVisualizations saved to: {viz_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d560f50",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated a complete data analysis pipeline:\n",
    "\n",
    "1. ✅ **Data Loading** - Loaded employee data from CSV\n",
    "2. ✅ **Data Cleaning** - Converted data types and verified data quality\n",
    "3. ✅ **Statistical Analysis** - Summary statistics, group analysis, and correlations\n",
    "4. ✅ **Visualization** - Multiple plot types to understand the data\n",
    "5. ✅ **Advanced Analysis** - Regression and outlier detection\n",
    "6. ✅ **Results Export** - Saved cleaned data and visualizations\n",
    "\n",
    "### Key Findings:\n",
    "- The dataset contains 20 employees across 4 departments\n",
    "- Salary correlates positively with age and performance score\n",
    "- Management positions have the highest average salaries\n",
    "- No missing values or duplicates were found\n",
    "\n",
    "### Next Steps:\n",
    "- Try loading the JSON sales data (`sales_data.json`)\n",
    "- Experiment with different cleaning strategies\n",
    "- Perform time-series analysis on hire dates\n",
    "- Create custom visualizations for specific insights"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
